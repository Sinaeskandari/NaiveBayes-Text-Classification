{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34kSvaXZejxP"
      },
      "source": [
        "# **NaiveBayes - Text Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAnj55oxdpiQ"
      },
      "source": [
        "## 1. IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElC24F9DdRxq",
        "outputId": "81e7647a-fdd0-4428-b770-435a4d9a63b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import imdb\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpXc193Vd30r"
      },
      "source": [
        "## 2. Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tXfDtZQhINU"
      },
      "source": [
        "### 2.1. Any data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jL5KqGCQhHZy"
      },
      "outputs": [],
      "source": [
        "word_index = imdb.get_word_index()\n",
        "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
        "\n",
        "def decode_sequence(s):\n",
        "    return \" \".join(inverted_word_index.get(i, '<UNK>') for i in s)\n",
        "\n",
        "train_data = [decode_sequence(i) for i in x_train]\n",
        "test_data = [decode_sequence(i) for i in x_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imQqe33JeZqS"
      },
      "source": [
        "## 3. Build Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opNqhDhai4oJ"
      },
      "source": [
        "### 3.1. Uni-Gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2LltG5vQjGJv"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "unigram = CountVectorizer(ngram_range=(1, 1), stop_words='english')\n",
        "unigram_train_data = unigram.fit_transform(train_data)\n",
        "unigram_test_data = unigram.transform(test_data)\n",
        "nb = MultinomialNB()\n",
        "nb.fit(unigram_train_data, y_train)\n",
        "unigram_preds = nb.predict(unigram_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I1UwalSjA63"
      },
      "source": [
        "### 3.2. Bi-Gram\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J4nmoJX7jG8-"
      },
      "outputs": [],
      "source": [
        "bigram = CountVectorizer(ngram_range=(2, 2), stop_words='english')\n",
        "bigram_train_data = bigram.fit_transform(train_data)\n",
        "bigram_test_data = bigram.transform(test_data)\n",
        "nb.fit(bigram_train_data, y_train)\n",
        "bigram_preds = nb.predict(bigram_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCICu7qpjI9z"
      },
      "source": [
        "### 3.3. Tri-Gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t70q9YLTjIWD"
      },
      "outputs": [],
      "source": [
        "trigram = CountVectorizer(ngram_range=(3, 3), stop_words='english')\n",
        "trigram_train_data = trigram.fit_transform(train_data)\n",
        "trigram_test_data = trigram.transform(test_data)\n",
        "nb.fit(trigram_train_data, y_train)\n",
        "trigram_preds = nb.predict(trigram_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJj1mXJJd7eR"
      },
      "source": [
        "## 4. Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcfxW01ceY_R",
        "outputId": "40bc6165-26b3-40c1-ac19-ba57fdbac557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unigram scores: {'recall': 0.75792, 'precision': 0.859787639531718, 'f1': 0.8056464985756198, 'accuracy': 0.81716}\n",
            "bigram scores: {'recall': 0.80376, 'precision': 0.8503597122302158, 'f1': 0.8264034546576188, 'accuracy': 0.83116}\n",
            "trigram scores: {'recall': 0.68016, 'precision': 0.7476914959106499, 'f1': 0.7123287671232876, 'accuracy': 0.72532}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
        "\n",
        "metrics = []\n",
        "for preds in [unigram_preds, bigram_preds, trigram_preds]:\n",
        "    metric = {'recall': recall_score(y_test, preds), 'precision': precision_score(y_test, preds), 'f1': f1_score(y_test, preds), 'accuracy': accuracy_score(y_test, preds)}\n",
        "    metrics.append(metric)\n",
        "\n",
        "print(f'unigram scores: {metrics[0]}')\n",
        "print(f'bigram scores: {metrics[1]}')\n",
        "print(f'trigram scores: {metrics[2]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKKSLKMHrBzU"
      },
      "source": [
        "## Good Luck!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "NLP_HW2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
